# -*- coding: utf-8 -*-
"""Project_Stellar.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15J02qDs34XujzJ7KI39eEzeLDGnr39cq

#  Support Vector Machine
# Classifying the Stars as Giants or Dwarves

### Importing the libraries
"""

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd

"""## Data Handling

### Importing the Dataset
"""

dataset = pd.read_csv('star.csv')

dataset.head()

"""### Preprcossing the Data"""

# Removing the String Column and convert to the numerical form
dataset['SpType'].value_counts() #Check the Spectral Types

def codes_modif(columnname, dataset):
    value_counts = dataset[columnname].value_counts()
    replacers = {value: index for index, value in enumerate(value_counts.index)}
    dataset[columnname] = dataset[columnname].map(replacers)
    return dataset

dataset = codes_modif("SpType", dataset)

dataset.head()

dataset['SpType'].value_counts()

X = dataset.iloc[:, :-1].values # Defining the X division
y = dataset.iloc[:, -1].values #Defining the y division, which is the result column

"""## Splitting into Training and Testing dataset"""

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)

print(X_train)

print(y_train)

print(X_test)

print(y_test)

"""## Feature Scaling"""

from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)

"""## Training the SVM Model on the Training Set"""

from sklearn.svm import SVC
classifier = SVC(kernel = 'linear', random_state = 0)
classifier.fit(X_train, y_train)

ans=classifier.predict(sc.transform([[5.99,13.73,0.58,1.318,14,16.678352]]))

if ans==0:
  print("The given Planet is Dwarf Planet")
else:
  print("The given Planet is Giant Planet")